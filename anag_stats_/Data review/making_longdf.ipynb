{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory notebook 2 After preliminary _qc.\n",
    "\n",
    "Here we make a subject wise df and start cleaning using the process developed in the preliminary qc notebook. We want to start looking at RT and thinking about what kind of things will warrant subject exclusion is what we look go get out of this. \n",
    "\n",
    "\n",
    "First is loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# update to the file name to be read\n",
    "# the header is the row that has the collumn names (zero indexed, and verify which is the header row before running)\n",
    "# the sep is the seperator of the data\n",
    "df = pd.read_csv(\"anagram_rating_pilot_filtered_20240808_1713.csv\", header=0, sep=',')\n",
    "# reading in the df from the prelim qc file\n",
    "statsdf = pd.read_csv(\"anagram_statistics20240819_1557.csv\", header=0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out the good trials, each trial each subject is it valid and then group by \n",
    "\n",
    "    1. dataframe of only anagram trials (delete the rows that aren't trials)\n",
    "    2. new collumn, for each response is it valid row by row\n",
    "\n",
    "Should be in a structure now that can be grouped by subject or by anagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to the qc but we will change direction \n",
    "long_df = df.filter(['workerid', 'id', 'anagram', 'response', 'rt', 'setRun']).dropna()\n",
    "long_df = long_df[~((long_df['id'] == 'practice') | (long_df['id']== 'end_confirm_subjid'))]\n",
    "long_df['id'] = long_df['id'].apply(lambda x: int(x))\n",
    "\n",
    "# use the stat_df to get the correct answers using the id to match with the correct anagram, this will mean doing a lamda such that for each id in long df we get the correct\n",
    "# anagram from the statsdf\n",
    "long_df['correct'] = long_df.apply(lambda x: statsdf[statsdf['id'] == x['id']]['correct'].values[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the qc process for checking validity \n",
    "We're making a collumn that will have a boolean to check that the answer is /isn't valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_responses = pd.read_csv(\"qc_responses.csv\", header=0, sep=',') \n",
    "# function to get unique strings from each row\n",
    "def get_unique_strings(row):\n",
    "    # Filter out NaN values\n",
    "    filtered = [item for item in row if pd.notna(item)]\n",
    "    # Return the unique values in the list\n",
    "    return list(set(filtered))\n",
    "answers = valid_responses.apply(get_unique_strings, axis=1)\n",
    "all_unique_answers = set(item for sublist in answers for item in sublist)\n",
    "# make sure the whole response column is in lower case\n",
    "long_df['response'] = long_df['response'].str.lower()\n",
    "# make a column in the long_df to check from inside the answers if the response is valid\n",
    "long_df['valid'] = long_df['response'].isin(all_unique_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups \n",
    "Now that there's a validity col in the long _df we can make groups to look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the worker id and get the see the number of valid responses\n",
    "worker_group = long_df.groupby('workerid')['valid'].sum()\n",
    "# make the workergroup a df\n",
    "worker_group = worker_group.reset_index()\n",
    "# make worker_group index \n",
    "worker_index = worker_group.columns.get_loc('workerid')\n",
    "# new collumn that's the rt for the valid responses for the worker_group\n",
    "worker_group['rt_mean'] = long_df[long_df['valid']].groupby('workerid')['rt'].mean()\n",
    "# insert the new collumn into the worker_group\n",
    "# cols = worker_group.columns.tolist()\n",
    "# cols.insert(worker_index +1, cols.pop(cols.index('rt_mean'))) \n",
    "# worker_group = worker_group[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always recomment the save file before a git push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# now = datetime.now()\n",
    "# dt_string = now.strftime(\"%Y%m%d_%H%M\")\n",
    "# timestamped = 'subject_stats' + dt_string + '.csv'\n",
    "# df.to_csv(timestamped, index=False)\n",
    "# subject_stats.drop(['response'], axis=1).to_csv(timestamped, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (miniconda3)",
   "language": "python",
   "name": "miniconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
