{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca7df1d",
   "metadata": {},
   "source": [
    "<h2> How to get the word strings code </h2>\n",
    "    \n",
    "This script gives us the words and then shuffles the sequences of the letters. The shuffling is added next to the solution for easy scripting down the line. \n",
    "\n",
    "The code chunks are compiled by Lynde@ but generated with assistance from GPT-4. This markdown shows in comments what are human and what are AI,  affectionatly named \"pelops\" and then numbered with each restart (as for generating some of the code the AI would loop and crash itself). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d166f",
   "metadata": {},
   "source": [
    "<h3> Five letter words </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c67cb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about, utoab',\n",
       " 'above, bovae',\n",
       " 'after, faetr',\n",
       " 'again, aaign',\n",
       " 'below, wlbeo',\n",
       " 'could, duloc',\n",
       " 'every, veyer',\n",
       " 'first, siftr',\n",
       " 'found, nuodf',\n",
       " 'great, retag',\n",
       " 'house, soeuh',\n",
       " 'large, lerag',\n",
       " 'learn, renla',\n",
       " 'never, rveen',\n",
       " 'other, threo',\n",
       " 'place, paecl',\n",
       " 'plant, ltanp',\n",
       " 'point, nptoi',\n",
       " 'right, itrgh',\n",
       " 'small, lmals',\n",
       " 'sound, nduso',\n",
       " 'spell, lslpe',\n",
       " 'still, tslil',\n",
       " 'study, sdtyu',\n",
       " 'their, eirth',\n",
       " 'there, eterh',\n",
       " 'these, thees',\n",
       " 'thing, ingth',\n",
       " 'think, itkhn',\n",
       " 'three, ereth',\n",
       " 'water, ewart',\n",
       " 'where, rwehe',\n",
       " 'which, hhicw',\n",
       " 'world, lwdro',\n",
       " 'would, oldwu',\n",
       " 'write, eitwr',\n",
       " 'young, noygu',\n",
       " 'quick, ciqku',\n",
       " 'quiet, etiqu',\n",
       " 'quite, iueqt',\n",
       " 'brown, nwrob',\n",
       " 'clear, celar',\n",
       " 'black, cablk',\n",
       " 'white, ihetw',\n",
       " 'green, eegrn',\n",
       " 'super, upesr',\n",
       " 'sweet, ewtes',\n",
       " 'stand, ntasd',\n",
       " 'start, sartt',\n",
       " 'state, atset',\n",
       " 'story, ytros',\n",
       " 'light, thigl',\n",
       " 'might, tmgih',\n",
       " 'night, hgtin',\n",
       " 'right, rhtgi',\n",
       " 'sight, tgshi',\n",
       " 'those, ohtse',\n",
       " 'under, unerd',\n",
       " 'while, liweh',\n",
       " 'angry, gyarn',\n",
       " 'birth, hbrit',\n",
       " 'death, ahtde',\n",
       " 'earth, htera',\n",
       " 'final, afinl',\n",
       " 'fresh, efsrh',\n",
       " 'heart, heart',\n",
       " 'month, nthmo',\n",
       " 'north, trnoh',\n",
       " 'party, rypat',\n",
       " 'peace, eaepc',\n",
       " 'piece, eipec',\n",
       " 'proud, oudrp',\n",
       " 'sense, sense',\n",
       " 'seven, esven',\n",
       " 'shall, alslh',\n",
       " 'short, rhtos',\n",
       " 'since, niecs',\n",
       " 'sixth, ithxs',\n",
       " 'thank, katnh',\n",
       " 'their, etrih',\n",
       " 'thing, gitnh',\n",
       " 'think, kitnh',\n",
       " 'third, ihrtd',\n",
       " 'three, etrhe',\n",
       " 'today, aytdo',\n",
       " 'total, altto',\n",
       " 'touch, touch',\n",
       " 'train, trani',\n",
       " 'treat, taetr',\n",
       " 'trial, ratli',\n",
       " 'trust, tsrtu',\n",
       " 'truth, truth',\n",
       " 'twice, tiwec',\n",
       " 'under, dnuer',\n",
       " 'until, tinul',\n",
       " 'usual, uausl',\n",
       " 'value, veaul',\n",
       " 'video, oveid',\n",
       " 'visit, isvti',\n",
       " 'voice, veoic',\n",
       " 'waste, tsawe',\n",
       " 'watch, whtca',\n",
       " 'water, ewatr',\n",
       " 'while, ewilh',\n",
       " 'white, twhie',\n",
       " 'whole, wlheo',\n",
       " 'woman, wamno',\n",
       " 'women, moewn',\n",
       " 'world, orwld',\n",
       " 'worry, rroyw',\n",
       " 'worse, wseor',\n",
       " 'worth, wtrho',\n",
       " 'write, ewitr',\n",
       " 'wrong, rnwgo',\n",
       " 'young, uygno',\n",
       " 'youth, yuoth',\n",
       " 'apple, palpe',\n",
       " 'chair, aicrh',\n",
       " 'clock, olcck',\n",
       " 'shelf, lsfeh']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this code chunk was generated by GPT-4.0 from \"Open\"Ai\n",
    "import random\n",
    "\n",
    "# List of commonly used 5-letter English words\n",
    "five_letter_words = [\n",
    "    \"about\", \"above\", \"after\", \"again\", \"below\", \"could\", \"every\", \"first\",\n",
    "    \"found\", \"great\", \"house\", \"large\", \"learn\", \"never\", \"other\", \"place\",\n",
    "    \"plant\", \"point\", \"right\", \"small\", \"sound\", \"spell\", \"still\", \"study\",\n",
    "    \"their\", \"there\", \"these\", \"thing\", \"think\", \"three\", \"water\", \"where\",\n",
    "    \"which\", \"world\", \"would\", \"write\", \"young\", \"quick\", \"quiet\", \"quite\",\n",
    "    \"brown\", \"clear\", \"black\", \"white\", \"green\", \"super\", \"sweet\", \"stand\",\n",
    "    \"start\", \"state\", \"story\", \"light\", \"might\", \"night\", \"right\", \"sight\",\n",
    "    \"those\", \"under\", \"while\", \"angry\", \"birth\", \"death\", \"earth\", \"final\",\n",
    "    \"fresh\", \"heart\", \"month\", \"north\", \"party\", \"peace\", \"piece\", \"proud\",\n",
    "    \"sense\", \"seven\", \"shall\", \"short\", \"since\", \"sixth\", \"thank\", \"their\",\n",
    "    \"thing\", \"think\", \"third\", \"three\", \"today\", \"total\", \"touch\", \"train\",\n",
    "    \"treat\", \"trial\", \"trust\", \"truth\", \"twice\", \"under\", \"until\", \"usual\",\n",
    "    \"value\", \"video\", \"visit\", \"voice\", \"waste\", \"watch\", \"water\", \"while\",\n",
    "    \"white\", \"whole\", \"woman\", \"women\", \"world\", \"worry\", \"worse\", \"worth\",\n",
    "    \"write\", \"wrong\", \"young\", \"youth\", \"apple\", \"chair\", \"clock\", \"shelf\",\n",
    "    \"table\", \"house\", \"money\", \"photo\", \"sugar\", \"honey\", \"drama\", \"fifty\"\n",
    "]\n",
    "\n",
    "# Shuffle each word's letters and pair them together\n",
    "shuffled_pairs_five = []\n",
    "for word in five_letter_words:\n",
    "    shuffled = list(word)\n",
    "    random.shuffle(shuffled)\n",
    "    shuffled_word = ''.join(shuffled)\n",
    "    shuffled_pairs_five.append(f\"{word}, {shuffled_word}\")\n",
    "\n",
    "shuffled_pairs_five[:120]  # Show the first 120 pairs as requested (list is exactly 120 words long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554a050",
   "metadata": {},
   "source": [
    "<h3> Six letter words and shuffled </h3>\n",
    "\n",
    "Six letter words were slightly more challenging but made in the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39620e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action, ancito',\n",
       " 'beauty, yuteba',\n",
       " 'change, caheng',\n",
       " 'damage, amdage',\n",
       " 'effect, ftcefe',\n",
       " 'flight, gtfihl',\n",
       " 'growth, tgworh',\n",
       " 'health, tleahh',\n",
       " 'island, anilsd',\n",
       " 'jungle, uejngl',\n",
       " 'kernel, nerkel',\n",
       " 'liquid, uliidq',\n",
       " 'method, hdoetm',\n",
       " 'nature, unerta',\n",
       " 'object, tbcejo',\n",
       " 'people, lepoep',\n",
       " 'quartz, aztuqr',\n",
       " 'record, orrecd',\n",
       " 'silver, srielv',\n",
       " 'travel, ltaerv',\n",
       " 'useful, uelufs',\n",
       " 'vacuum, umcuav',\n",
       " 'wealth, lwhate',\n",
       " 'yellow, wellyo',\n",
       " 'zephyr, zyrhep',\n",
       " 'abroad, aardob',\n",
       " 'breeze, eezbre',\n",
       " 'circle, cirelc',\n",
       " 'desert, dtsere',\n",
       " 'energy, eyergn',\n",
       " 'father, atfreh',\n",
       " 'garden, ardgne',\n",
       " 'hammer, maherm',\n",
       " 'injury, yinujr',\n",
       " 'jacket, kcjeta',\n",
       " 'killer, erlilk',\n",
       " 'laptop, tpopal',\n",
       " 'mirror, irrmro',\n",
       " 'needle, ldenee',\n",
       " 'office, efofic',\n",
       " 'pencil, pcienl',\n",
       " 'quiver, euqvri',\n",
       " 'reason, raosen',\n",
       " 'spirit, srtpii',\n",
       " 'temple, etpmle',\n",
       " 'update, eudapt',\n",
       " 'vision, invsoi',\n",
       " 'wallet, altelw',\n",
       " 'xenial, ilaxne',\n",
       " 'yearly, layeyr',\n",
       " 'zodiac, oiazdc',\n",
       " 'afford, afrofd',\n",
       " 'branch, crabnh',\n",
       " 'charge, cgrahe',\n",
       " 'danger, eradng',\n",
       " 'empire, peirme',\n",
       " 'fossil, lsfosi',\n",
       " 'guitar, irutag',\n",
       " 'harbor, hrbrao',\n",
       " 'import, mirtop',\n",
       " 'juggle, glejug',\n",
       " 'kitten, tintek',\n",
       " 'league, gluaee',\n",
       " 'market, aektrm',\n",
       " 'narrow, nrwora',\n",
       " 'orange, roegna',\n",
       " 'patent, tnetap',\n",
       " 'quaint, ntiuaq',\n",
       " 'return, eunrrt',\n",
       " 'simple, slmiep',\n",
       " 'tissue, sstiue',\n",
       " 'urgent, tenrug',\n",
       " 'violet, ltiveo',\n",
       " 'wrench, wnherc',\n",
       " 'yellow, llyewo',\n",
       " 'zombie, zoemib',\n",
       " 'amount, anomut',\n",
       " 'beacon, ceoabn',\n",
       " 'candle, necdal',\n",
       " 'decade, cdaeed',\n",
       " 'export, optexr',\n",
       " 'frozen, znrefo',\n",
       " 'gossip, pisgso',\n",
       " 'honest, stenoh',\n",
       " 'impact, cmiapt',\n",
       " 'junior, uionrj',\n",
       " 'kidney, kdeyni',\n",
       " 'legend, gledne',\n",
       " 'magnet, meantg',\n",
       " 'novice, cevoin',\n",
       " 'option, poonit',\n",
       " 'pillar, llirpa',\n",
       " 'quorum, mqoruu',\n",
       " 'recipe, ierepc',\n",
       " 'sponge, peongs',\n",
       " 'target, tgarte',\n",
       " 'unique, uiuqen',\n",
       " 'valley, aellyv',\n",
       " 'wonder, wdneor',\n",
       " 'youths, osuyht',\n",
       " 'zigzag, agzigz',\n",
       " 'admire, armied',\n",
       " 'branch, crhabn',\n",
       " 'choice, ehoicc',\n",
       " 'damage, gedmaa',\n",
       " 'exotic, extico',\n",
       " 'family, amlyif',\n",
       " 'global, aobgll',\n",
       " 'heroic, ceirho',\n",
       " 'island, nsiadl',\n",
       " 'joyful, oluyfj',\n",
       " 'knotty, yntotk',\n",
       " 'little, ileltt',\n",
       " 'medium, iummed',\n",
       " 'normal, nolmra',\n",
       " 'online, linoen',\n",
       " 'prince, ipcrne',\n",
       " 'square, qaeurs',\n",
       " 'tongue, eontgu',\n",
       " 'update, uaetpd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##this code chunk was generated by GPT-4.0 from \"Open\"Ai\n",
    "import random\n",
    "# List of commonly used 6-letter English words\n",
    "six_letter_words = [\n",
    "    \"action\", \"beauty\", \"change\", \"damage\", \"effect\", \"flight\", \"growth\", \"health\",\n",
    "    \"island\", \"jungle\", \"kernel\", \"liquid\", \"method\", \"nature\", \"object\", \"people\",\n",
    "    \"quartz\", \"record\", \"silver\", \"travel\", \"useful\", \"vacuum\", \"wealth\", \"yellow\",\n",
    "    \"zephyr\", \"abroad\", \"breeze\", \"circle\", \"desert\", \"energy\", \"father\", \"garden\",\n",
    "    \"hammer\", \"injury\", \"jacket\", \"killer\", \"laptop\", \"mirror\", \"needle\", \"office\",\n",
    "    \"pencil\", \"quiver\", \"reason\", \"spirit\", \"temple\", \"update\", \"vision\", \"wallet\",\n",
    "    \"xenial\", \"yearly\", \"zodiac\", \"afford\", \"branch\", \"charge\", \"danger\", \"empire\",\n",
    "    \"fossil\", \"guitar\", \"harbor\", \"import\", \"juggle\", \"kitten\", \"league\", \"market\",\n",
    "    \"narrow\", \"orange\", \"patent\", \"quaint\", \"return\", \"simple\", \"tissue\", \"urgent\",\n",
    "    \"violet\", \"wrench\", \"yellow\", \"zombie\", \"amount\", \"beacon\", \"candle\", \"decade\",\n",
    "    \"export\", \"frozen\", \"gossip\", \"honest\", \"impact\", \"junior\", \"kidney\", \"legend\",\n",
    "    \"magnet\", \"novice\", \"option\", \"pillar\", \"quorum\", \"recipe\", \"sponge\", \"target\",\n",
    "    \"unique\", \"valley\", \"wonder\", \"youths\", \"zigzag\", \"admire\", \"branch\", \"choice\",\n",
    "    \"damage\", \"exotic\", \"family\", \"global\", \"heroic\", \"island\", \"joyful\", \"knotty\",\n",
    "    \"little\", \"medium\", \"normal\", \"online\", \"prince\", \"square\", \"tongue\", \"update\",\n",
    "    \"visual\", \"window\", \"yacht\", \"zodiac\"\n",
    "]\n",
    "\n",
    "# Shuffle each word's letters and pair them together\n",
    "shuffled_six_pairs = []\n",
    "for word in six_letter_words:\n",
    "    shuffled = list(word)\n",
    "    random.shuffle(shuffled)\n",
    "    shuffled_word = ''.join(shuffled)\n",
    "    shuffled_six_pairs.append(f\"{word}, {shuffled_word}\")\n",
    "\n",
    "shuffled_six_pairs[:120]  # Show the first 120 pairs as requested (list is exactly 120 words long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0cb7f",
   "metadata": {},
   "source": [
    "<h3> Four letter words </h3>\n",
    "    \n",
    "Significantly more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1fe59",
   "metadata": {},
   "source": [
    "<h3> Finaly the four letter words </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d1d927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that, atht',\n",
       " 'with, hitw',\n",
       " 'this, siht',\n",
       " 'from, rfmo',\n",
       " 'your, uryo',\n",
       " 'have, heva',\n",
       " 'they, yteh',\n",
       " 'will, lwli',\n",
       " 'what, athw',\n",
       " 'when, henw',\n",
       " 'then, ehtn',\n",
       " 'them, ehmt',\n",
       " 'some, oems',\n",
       " 'take, ktea',\n",
       " 'into, tnio',\n",
       " 'time, mtie',\n",
       " 'like, lkei',\n",
       " 'more, orme',\n",
       " 'very, rvye',\n",
       " 'know, okwn',\n",
       " 'than, naht',\n",
       " 'want, wnat',\n",
       " 'text, xett',\n",
       " 'back, ckab',\n",
       " 'give, vgie',\n",
       " 'most, ostm',\n",
       " 'also, osal',\n",
       " 'down, donw',\n",
       " 'over, ervo',\n",
       " 'much, uhcm',\n",
       " 'need, eend',\n",
       " 'feel, eefl',\n",
       " 'come, omec',\n",
       " 'love, elvo',\n",
       " 'play, ylap',\n",
       " 'find, fdin',\n",
       " 'move, ovme',\n",
       " 'even, neve',\n",
       " 'live, leiv',\n",
       " 'help, ehlp',\n",
       " 'line, nlei',\n",
       " 'work, wokr',\n",
       " 'part, atrp',\n",
       " 'next, nxte',\n",
       " 'call, clal',\n",
       " 'talk, lkta',\n",
       " 'plus, lpsu',\n",
       " 'away, aywa',\n",
       " 'sure, ersu',\n",
       " 'seem, esem',\n",
       " 'stay, asty',\n",
       " 'turn, rnut',\n",
       " 'hard, hrad',\n",
       " 'page, epag',\n",
       " 'read, edar',\n",
       " 'left, lfet',\n",
       " 'stop, tosp',\n",
       " 'keep, eekp',\n",
       " 'face, cafe',\n",
       " 'city, yict',\n",
       " 'best, steb',\n",
       " 'tell, letl',\n",
       " 'hear, rahe',\n",
       " 'hope, phoe',\n",
       " 'life, lfei',\n",
       " 'cost, tcso',\n",
       " 'wait, wati',\n",
       " 'plan, plna',\n",
       " 'true, ertu',\n",
       " 'many, aynm',\n",
       " 'idea, eaid',\n",
       " 'body, yodb',\n",
       " 'info, nofi',\n",
       " 'game, mgae',\n",
       " 'care, crae',\n",
       " 'last, stla',\n",
       " 'team, mtae',\n",
       " 'week, weke',\n",
       " 'note, otne',\n",
       " 'show, oshw',\n",
       " 'able, laeb',\n",
       " 'hand, hdna',\n",
       " 'view, eviw',\n",
       " 'home, meoh',\n",
       " 'site, iset',\n",
       " 'case, acse',\n",
       " 'most, otms',\n",
       " 'road, droa',\n",
       " 'test, etst',\n",
       " 'copy, cpoy',\n",
       " 'step, spte',\n",
       " 'user, esur',\n",
       " 'baby, byab',\n",
       " 'base, esab',\n",
       " 'miss, sims',\n",
       " 'love, vole',\n",
       " 'risk, irsk',\n",
       " 'fish, fhsi',\n",
       " 'blue, ulbe',\n",
       " 'form, mofr',\n",
       " 'pass, ssap',\n",
       " 'camp, apmc',\n",
       " 'lead, aled',\n",
       " 'sale, lesa',\n",
       " 'club, bluc',\n",
       " 'army, ryam',\n",
       " 'band, bdna',\n",
       " 'bill, ilbl',\n",
       " 'mass, amss',\n",
       " 'card, adrc',\n",
       " 'list, lsti',\n",
       " 'slip, plis',\n",
       " 'tree, eret',\n",
       " 'race, reca',\n",
       " 'ball, blal',\n",
       " 'sink, nkis',\n",
       " 'coat, atco',\n",
       " 'milk, ilkm',\n",
       " 'sand, ansd',\n",
       " 'jazz, zzaj']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "# Pelops 3:\n",
    "four_letter_words = [\n",
    "    'that', 'with', 'this', 'from', 'your', 'have', 'they', 'will', 'what', 'when', 'then', 'them', 'some', 'take', 'into',\n",
    "    'time', 'look', 'like', 'more', 'very', 'know', 'than', 'want', 'text', 'back', 'good', 'give', 'most', 'also', 'down',\n",
    "    'over', 'much', 'need', 'feel', 'come', 'love', 'play', 'find', 'move', 'even', 'live', 'help', 'line', 'work', 'part',\n",
    "    'next', 'call', 'talk', 'plus', 'away', 'sure', 'seem', 'food', 'stay', 'turn', 'hard', 'page', 'read', 'left', 'soon',\n",
    "    'stop', 'keep', 'face', 'city', 'best', 'tell', 'hear', 'hope', 'room', 'door', 'life', 'cost', 'wait', 'plan', 'true',\n",
    "    'many', 'idea', 'body', 'info', 'book', 'game', 'care', 'last', 'team', 'week', 'note', 'show', 'able', 'hand', 'view',\n",
    "    'home', 'site', 'case', 'most', 'road', 'test', 'copy', 'step', 'user', 'baby', 'base', 'miss', 'love', 'risk', 'fish',\n",
    "    'blue', 'form', 'pass', 'camp', 'lead', 'sale', 'club', 'army', 'band', 'pool', 'bill', 'foot', 'mass', 'card', 'list',\n",
    "    'slip', 'tree', 'race', 'ball', 'sink', 'coat', 'milk', 'sand', 'jazz', 'type', 'film', 'burn', 'bolt', 'golf', 'wolf',\n",
    "    'lamp', 'salt', 'gold', 'soap', 'roof', 'limb', 'clay', 'lamb', 'mild', 'bald', 'bold', 'disk', 'deck', 'dusk', 'peak',\n",
    "    'pork', 'fork', 'bark'\n",
    "]\n",
    "\n",
    "#ok I need to fix such that there are no \"-oo-\" words otherwise the shuffle check isn't working\n",
    "\n",
    "##Pelops3 code:\n",
    "\n",
    "# Filtering out words with two 'o' from the original list\n",
    "filtered_words = [word for word in four_letter_words if word.count('o') < 2]\n",
    "\n",
    "# Common four-letter words without duplicates from the original list, excluding words with two 'o's\n",
    "additional_replacement_words = [\n",
    "    'cold', 'warm', 'wild', 'wise', 'tall', 'thin', 'tiny', 'rich', 'poor', 'neat', 'lazy', 'kind', 'huge', 'full', 'firm',\n",
    "    'fair', 'easy', 'dark', 'cute', 'calm', 'busy', 'bold', 'bald', 'awed', 'avid', 'arts', 'arms', 'arch', 'apps', 'ants',\n",
    "    'ankh', 'amps', 'alps', 'ally', 'alas', 'akin', 'aide', 'ages', 'aero', 'adds', 'acid', 'aces'\n",
    "]\n",
    "\n",
    "# We need to add enough words to bring the total back up to 153\n",
    "number_of_words_needed = 153 - len(filtered_words)\n",
    "replacement_words = []\n",
    "\n",
    "for word in additional_replacement_words:\n",
    "    if word not in four_letter_words and len(replacement_words) < number_of_words_needed:\n",
    "        replacement_words.append(word)\n",
    "\n",
    "# Combine the filtered list with the new unique replacement words\n",
    "final_four_letter_words = filtered_words + replacement_words\n",
    "len(final_four_letter_words), final_four_letter_words\n",
    "\n",
    "#I moved this code chunk\n",
    "shuffled_four_pairs = []\n",
    "for word in final_four_letter_words:\n",
    "    shuffled = list(word)\n",
    "    while True:\n",
    "        random.shuffle(shuffled)\n",
    "        shuffled_word = ''.join(shuffled)\n",
    "        if shuffled_word != word:\n",
    "            break\n",
    "    shuffled_four_pairs.append(f\"{word}, {shuffled_word}\")\n",
    "\n",
    "shuffled_four_pairs[:120]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf7d84",
   "metadata": {},
   "source": [
    "<h3> Concatinate and create the blocks </h3>\n",
    "\n",
    "So now we need to make the stimuli for each of the blocks. For this we want to have 10 strings of each length per block for 3 blocks. \n",
    "\n",
    "And then we make groups of those until all the words are assigned. Finally, we will collect 10-30 participants per group. \n",
    "\n",
    "So in total: 3 blocks of 30 anagrams which will be 10 four letters, 10 five letters, 10 six letters. To make sure we get all the words, we will need 4 groups to have the 120 words for each string length represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3f61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a distributing function to spread the words across the four groups\n",
    "def distribute_words(word_list, num_groups=4):\n",
    "    # Calculate the number of words per group\n",
    "    group_size = len(word_list) // num_groups\n",
    "    \n",
    "    # Create groups\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    \n",
    "    # Distribute words to each group\n",
    "    for index, word in enumerate(word_list):\n",
    "        group_index = index // group_size\n",
    "        if group_index < num_groups:  # This check prevents index out of range if not perfectly divisible\n",
    "            groups[group_index].append(word)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "\n",
    "# Distribute words to the groups\n",
    "grouped_four_letter_words = distribute_words(shuffled_four_pairs)\n",
    "grouped_five_letter_words = distribute_words(shuffled_pairs_five)\n",
    "grouped_six_letter_words = distribute_words(shuffled_six_pairs)\n",
    "\n",
    "# Save each group to a separate CSV file\n",
    "import csv\n",
    "for i in range(4):\n",
    "    filename = f'group_{i+1}_word_pairs.csv'\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Type', 'Word Pairs'])\n",
    "        \n",
    "        writer.writerows([['Four-Letter', word] for word in grouped_four_letter_words[i]])\n",
    "        writer.writerows([['Five-Letter', word] for word in grouped_five_letter_words[i]])\n",
    "        writer.writerows([['Six-Letter', word] for word in grouped_six_letter_words[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555b9ca",
   "metadata": {},
   "source": [
    "Okay now we need to create the stimuli file which should be in a .js that will look like: \n",
    "\n",
    "let trial_objects = [\n",
    "    {\n",
    "        \"id\": \"001\",\n",
    "        \"type\": \"Four-Letter\",\n",
    "        \"anagram\": \"atth\",\n",
    "        \"correct\": \"that\",\n",
    "        \"set\": \"A\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7bba816",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Set_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m js_entries\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Placeholder for all JS entries\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m all_entries \u001b[38;5;241m=\u001b[39m [csv_to_js_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./group_1_word_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, Set_A),\n\u001b[1;32m     25\u001b[0m                csv_to_js_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./group_2_word_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, Set_B),\n\u001b[1;32m     26\u001b[0m                csv_to_js_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./group_3_word_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, Set_C),\n\u001b[1;32m     27\u001b[0m                csv_to_js_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./group_4_word_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, Set_D)]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Loop over each CSV file and set name\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Set_A' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_directory = \"./group_1_word_pairs.csv\", \"./group_2_word_pairs.csv\", \"./group_3_word_pairs.csv\", \"./group_4_word_pairs.csv\"\n",
    "\n",
    "# Function to convert CSV content to JS format\n",
    "def csv_to_js_format(csv_content, word_type, set_name):\n",
    "    js_entries = []\n",
    "    for idx, row in enumerate(csv_content):\n",
    "        word_type, word_pair = row\n",
    "        if idx == 0:  # Skip header row\n",
    "            continue\n",
    "        original, anagram = word_pair.split(\", \")\n",
    "        js_entry = {\n",
    "            \"id\": f\"{str(idx).zfill(3)}\",\n",
    "            \"type\": word_type,\n",
    "            \"anagram\": anagram,\n",
    "            \"correct\": original,\n",
    "            \"set\": set_name\n",
    "        }\n",
    "        js_entries.append(js_entry)\n",
    "    return js_entries\n",
    "\n",
    "\n",
    "# Placeholder for all JS entries\n",
    "all_entries = [csv_to_js_format(\"./group_1_word_pairs.csv\", Set_A),\n",
    "               csv_to_js_format(\"./group_2_word_pairs.csv\", Set_B),\n",
    "               csv_to_js_format(\"./group_3_word_pairs.csv\", Set_C),\n",
    "               csv_to_js_format(\"./group_4_word_pairs.csv\", Set_D)]\n",
    "\n",
    "# Loop over each CSV file and set name\n",
    "for i in range(4):\n",
    "    filename = f'group_{i+1}_word_pairs.csv'\n",
    "    set_name = f\"Set{chr(65 + i)}\"  # 'SetA', 'SetB', 'SetC', 'SetD'\n",
    "    \n",
    "    with open(filename, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        js_entries = csv_to_js_format(csvreader, set_name)\n",
    "        all_entries.extend(js_entries)\n",
    "\n",
    "# Save all entries into the JS file\n",
    "stimuli_js_content = \"let trial_objects = \" + str(all_entries) + \";\"\n",
    "with open(\"stimuli.js\", \"w\") as file:\n",
    "    file.write(stimuli_js_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f7a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python (miniconda3)",
   "language": "python",
   "name": "miniconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
